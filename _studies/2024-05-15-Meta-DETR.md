---
layout: post
title: Meta DETR
tags: 
- Deep Learning
- Review
- Object Detection
- Meta Learning
- Few shot
math: true
date: 2024-05-15
---

# Meta-detr

- fewshot learning : 잘 알고 있는 base class  이용 → 적은 양의 샘플이 있는 novel class 학습
- metric based learning : Inter class correlation 정보를 사용하기 위한 attention module ( = CAM) 제안

### DETR

- Meta-DETR 의 디반 되는 모델 : [[2005.12872] End-to-End Object Detection with Transformers (arxiv.org)](https://arxiv.org/abs/2005.12872)
- Detection 문제를 Transformer 로 접근함

<img src="images\캡처.JPG (1).jpg" width="550px">

- 이미지는 CNN Backbone, transformer 구조를 통과해 d 차원 hidden state 를 갖게됨.
- d 차원 hidden state 를 Linear layer 를 사용하여 쿼리 개수 만큼 class, box embedding 시킴.
- Loss 는 Hungarian algorithm 을 사용해 쿼리와 타겟을 매칭시킴.
- 네트워크에 RPN, FPN ,NMS, Anchor box 없음.

### CAM (Correalational Aggregation Module)

- Meta DETR 의 핵심 구조, Attention Module 로 encoder 속에 있음.
- 나머지 구조는 DETR 과 유사함

<img src="images\캡처.JPG (2).jpg" width="550px">

- Query feature 와 랜덤 샘플링한 support feature 를 각각 Attention 의 query, key 값으로 넣어준다.
- Attention coefficent : $$A = \mathbf{Softmax} \left( \frac {\mathbf{(QW)} \mathbf{(SW)}^T} {\sqrt{d}} \right)$$, 
where $d$ = the number of dimension , Q = query feature, S = support feature, W = learnable parameters (Linear projection)
- 위와 같이 어탠션을 준다면, Query image 와 support image 의 feature 가 잘 aggregation 될 것이다.