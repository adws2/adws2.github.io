---
layout: post
title: YOLO-R
tags: 
- Deep Learning
- Review
- Object Detection
math: true
date: 2024-05-15
---
# 비공개
$\bf$
# YOLO-R

- 명시적 지식과 암시적 지식을 결합하여 모델 성능을 이끌어 내보자

### Introdection

- 사람은 데이터를 다양한 각도로 해석 가능함 → 모델은 잘 못함
- 이러한 컨셉을 Multi-task 관점으로 볼 수 있다.
- 위 문제를 잘 해결하기 위해서 Implicit knowledge 와 explicit knowledge 를 introducing
    
    
    |  | layer | corresponding observation | related work |
    | --- | --- | --- | --- |
    | explicit knowledge | shallow | directly | feature selection, transformer |
    | implicit knowledge | deep | nothing | implicit NN, deep equilibrium models,  |

- YOLOR은 implicit knowlege 를 잘 추출하기 위해 unified network 사용.
unified network 기법은 적은 양의 파라미터 증가 만으로도 성능 증가가 좋음
- implicit knowledge learning process
→ kernel space alignment, prediction refinement, multi-task learning

- REFERENCES : 저자들의 이전 연구에서 unified network 을 다뤘다고 함  [16,17,18]
unified network 의 자세한 설명이 필요하다면 이전 연구들을 공부해야 할 듯.
knowledge modeling [1, 12, 22, 23]

#### Implicit knowledge

- $Z = \{  z_1 , z_2, ..., z_k \}$ ← implicit representation, constant tensor
- task specific Implicit knowledge 와 input feature 간 내적을 이용해 해당 task에 맞는 good representation space 를 찾을 수 있음
- Z  의 생김새는 vector, tensor, factorized matrix 일 수 있음
제약은 없지만, 논문에서는 생김새가 어떤지에 따라 모델의 성능을 테스트함
- Z 는 normal initialize 되어있음. ( 인풋값에 따라 independent )

### Theory

<img src="images\화면 캡처 2022-05-23 183158.png" width="650px">

- feature alignment 를 통해 성능을 이끌어냄
- good representation 를 찾는 것 → manifold space 에서 적절하게 projection 하는 것
- manifold space 에서 projection 을 여러 번 수행함 → alignment 를 시켜줄 수 있는 추가 parameter, network (implicit knowledge) 필요.

<img src="images\화면 캡처 2022-05-25 143523.jpg" width="650px">

- (a) 일반적인 ML 은 타겟과 예측의 오류를 최소화 함
→ 이렇게 하면 다른 테스크에는 해당 representation 을 써먹을 수 x
- (b) 우리가 원하는 것은 적당히 relax $\epsilon$ → 모든 테스크를 고려한 에러
- (c) $\epsilon$    →  $\epsilon + g_\phi (\epsilon_{ex}(\mathbf{x}), \epsilon_{im} (\mathbf{z}) )$

where, $g_{\phi}$ is task specific operation (combine or select information from ex, implicit knowledge)

ex. offset refinement, anchor refinement, feature selection

- multi task equation , where $\Psi$ is final output parameters
$F ( \mathbf{x}, \theta, \mathbf{Z}, \Phi, Y , \Psi ) = 0$
- For different tasks
$d_{\Psi} (f_\theta(\mathbf{x}) , g_{\Phi} (\mathbf{z}) ,y) = 0$

<img src="images\캡처.JPG.jpg" width="650px" >

- YOLO-R 은 위에서 소개된 implicit knowledge 를 위 architecture 처럼 사용함
각 화살표가 implicit knowledge 를 집어넣었다는 표시임
- 즉, 해당 위치에 임배딩을 하나 생성해주는 것임.

### Code view

<img src="images\Untitled (1).png" width="450px">

i : FPN 에서 i 번째 scale

x : last hidden feature [ bs x channel x width x height Tensor ]

self.im : implicitM module (아래 참조)

self.ia : implicitA module (아래 참조)

self.m : 모델의 마지막 layer

→ 해석 : self.ia, self.im 이 없다면 layer 를 통과하는 일반적인 feature 를 나타냄.
두 모듈이 추가됨 으로, feature alignment 를 한 후, last layer 를 통과하여, prediction refinement 를 수행했다고 볼 수 있음.

<img src="images\Untitled.png" width="650px" >

- ImplicitA : feature alignment 할 수 있게하는 모듈.
단순히 1차원 nn parameter 를 4차원으로 expand 해서 feature 에 더해주는 연산

- implicitM :prediction refinement 할 수 있게하는 모듈.
단순히 1차원 nn parameter 를 4차원으로 expand 해서 feature 에 곱해주는 연산
곱해주어야 하기 때문에 initialization 할때, 평균을 1로 둔다.